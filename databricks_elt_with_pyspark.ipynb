{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c6cb2ae8-28c0-45c6-b754-5b15c70d19b5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "56cab98e-d9ed-4402-a253-13ba5298ddae",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### I. Bronze tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "deee454c-5cba-43e4-80ea-cada78cd7b6b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 1. Ingest raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc5e117a-4c65-426e-9d9c-9d3ae9bb9ce1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define file paths\n",
    "payments_path = \"dbfs:/FileStore/data/payments.csv\"\n",
    "riders_path = \"dbfs:/FileStore/data/riders.csv\"\n",
    "stations_path = \"dbfs:/FileStore/data/stations.csv\"\n",
    "trips_path = \"dbfs:/FileStore/data/trips.csv\"\n",
    "\n",
    "# Read CSV files with schemas\n",
    "# Payments data\n",
    "payments_schema = StructType([\n",
    "    StructField(\"payment_id\", IntegerType(), True),\n",
    "    StructField(\"payment_date\", TimestampType(), True),\n",
    "    StructField(\"payment_amount\", FloatType(), True),\n",
    "    StructField(\"acc_number\", IntegerType(), True),\n",
    "])\n",
    "payments_df = spark.read.csv(payments_path, header=False, schema=payments_schema)\n",
    "\n",
    "# Riders data\n",
    "riders_schema = StructType([\n",
    "    StructField(\"acc_number\", IntegerType(), True),\n",
    "    StructField(\"fname\", StringType(), True),\n",
    "    StructField(\"lname\", StringType(), True),\n",
    "    StructField(\"home_address\", StringType(), True),\n",
    "    StructField(\"dob\", TimestampType(), True),\n",
    "    StructField(\"start_date\", TimestampType(), True),\n",
    "    StructField(\"end_date\", TimestampType(), True),\n",
    "    StructField(\"membership_status\", BooleanType(), True),\n",
    "])\n",
    "riders_df = spark.read.csv(riders_path, header=False, schema=riders_schema)\n",
    "\n",
    "# Stations data\n",
    "stations_schema = StructType([\n",
    "    StructField(\"station_id\", StringType(), True),\n",
    "    StructField(\"station_name\", StringType(), True),\n",
    "    StructField(\"latitude\", FloatType(), True),\n",
    "    StructField(\"longitude\", FloatType(), True)\n",
    "])\n",
    "stations_df = spark.read.csv(stations_path, header=False, schema=stations_schema)\n",
    "\n",
    "# Trips data\n",
    "trips_schema = StructType([\n",
    "    StructField(\"trip_id\", StringType(), True),\n",
    "    StructField(\"type_of_rideable\", StringType(), True),\n",
    "    StructField(\"start_time\", TimestampType(), True),\n",
    "    StructField(\"end_time\", TimestampType(), True),\n",
    "    StructField(\"start_station\", StringType(), True),\n",
    "    StructField(\"end_station\", StringType(), True),\n",
    "    StructField(\"acc_number\", IntegerType(), True)\n",
    "])\n",
    "trips_df = spark.read.csv(trips_path, header=False, schema=trips_schema)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "147f5272-b4a9-4b39-911b-77dbda585336",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 2. Write data as delta tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d82f596-10d8-4dd8-98a8-e1880f186e35",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Save DataFrames as Delta tables\n",
    "payments_df.write.format(\"delta\")\\\n",
    "        .mode(\"overwrite\")\\\n",
    "        .option(\"overwriteSchema\", \"true\")\\\n",
    "        .save(\"/delta/bronze_payments\")\n",
    "\n",
    "riders_df.write.format(\"delta\")\\\n",
    "        .mode(\"overwrite\")\\\n",
    "        .option(\"overwriteSchema\", \"true\")\\\n",
    "        .save(\"/delta/bronze_riders\")\n",
    "\n",
    "stations_df.write.format(\"delta\")\\\n",
    "        .mode(\"overwrite\")\\\n",
    "        .option(\"overwriteSchema\", \"true\")\\\n",
    "        .save(\"/delta/bronze_stations\")\n",
    "\n",
    "trips_df.write.format(\"delta\")\\\n",
    "        .mode(\"overwrite\")\\\n",
    "        .option(\"overwriteSchema\", \"true\")\\\n",
    "        .save(\"/delta/bronze_trips\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "35585121-9ad9-40e2-a541-749216398ea4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### III. Silver tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e23bb4c-1de5-4d81-8d85-410919ae1480",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 1. Read data from bronze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c01f392-dd9f-49e7-8045-86693bc4e462",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define Delta table paths\n",
    "payments_delta_path = \"dbfs:/delta/bronze_payments\"\n",
    "riders_delta_path = \"dbfs:/delta/bronze_riders\"\n",
    "stations_delta_path = \"dbfs:/delta/bronze_stations\"\n",
    "trips_delta_path = \"dbfs:/delta/bronze_trips\"\n",
    "\n",
    "# Load Delta tables\n",
    "# Payments DataFrame\n",
    "payments_df = spark.read.format(\"delta\")\\\n",
    "                .option(\"inferSchema\", \"false\")\\\n",
    "                .option(\"header\", \"true\")\\\n",
    "                .load(payments_delta_path)\n",
    "\n",
    "# Riders DataFrame\n",
    "riders_df = spark.read.format(\"delta\")\\\n",
    "            .option(\"inferSchema\", \"false\")\\\n",
    "            .option(\"header\", \"true\")\\\n",
    "            .load(riders_delta_path)\n",
    "\n",
    "# Stations DataFrame\n",
    "stations_df = spark.read.format(\"delta\")\\\n",
    "            .option(\"inferSchema\", \"false\")\\\n",
    "            .option(\"header\", \"true\")\\\n",
    "            .load(stations_delta_path)\n",
    "\n",
    "# Trips DataFrame\n",
    "trips_df = spark.read.format(\"delta\")\\\n",
    "            .option(\"inferSchema\", \"false\")\\\n",
    "            .option(\"header\", \"true\")\\\n",
    "            .load(trips_delta_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d9ba52c6-c875-4d84-a1c8-45d85e0a21bf",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 2. Remove null and duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b4582130-ba5b-4da7-a4aa-c2a2dcb83c54",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Drop rows with null values in key columns\n",
    "payments_clean_df = payments_df.na.drop(subset=[\"payment_id\"])\n",
    "riders_clean_df = riders_df.na.drop(subset=[\"acc_number\"])\n",
    "stations_clean_df = stations_df.na.drop(subset=[\"station_id\", \"station_name\"])\n",
    "trips_clean_df = trips_df.na.drop(subset=[\"trip_id\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9aa0ecb4-9a49-4c7a-bd26-ebbabb8ec64f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Remove duplicate rows from DataFrames\n",
    "payments_clean_df = payments_clean_df.dropDuplicates()\n",
    "riders_clean_df = riders_clean_df.dropDuplicates()\n",
    "stations_clean_df = stations_clean_df.dropDuplicates()\n",
    "trips_clean_df = trips_clean_df.dropDuplicates()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "42b97630-a6c9-49b4-ad31-925a194005c0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 3. Save as tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02848ebe-bda9-43ab-84e6-0bde4da7d1e3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Save cleaned DataFrames as Delta tables\n",
    "payments_clean_df.write.format(\"delta\")\\\n",
    "        .mode(\"overwrite\")\\\n",
    "        .saveAsTable(\"silver_payments\")\n",
    "\n",
    "riders_clean_df.write.format(\"delta\")\\\n",
    "        .mode(\"overwrite\")\\\n",
    "        .saveAsTable(\"silver_riders\")\n",
    "\n",
    "stations_clean_df.write.format(\"delta\")\\\n",
    "        .mode(\"overwrite\")\\\n",
    "        .saveAsTable(\"silver_stations\")\n",
    "\n",
    "trips_clean_df.write.format(\"delta\")\\\n",
    "        .mode(\"overwrite\")\\\n",
    "        .saveAsTable(\"silver_trips\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8db8c067-e330-447a-9bf6-c75cf7c10893",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### III. Gold tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0efe3085-b1c1-4ec1-aa28-b29354b42887",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 1. Read data from silver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "118ed500-49c3-4be8-a389-51aea7c992bc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load Delta tables into DataFrames\n",
    "silver_payments_df = spark.table(\"silver_payments\")\n",
    "silver_riders_df = spark.table(\"silver_riders\")\n",
    "silver_stations_df = spark.table(\"silver_stations\")\n",
    "silver_trips_df = spark.table(\"silver_trips\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d9ad8ca-b626-4dec-8e7e-c24937e3ef9e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 2. Create fact and dimension tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b81389f-dd73-469f-92ed-037880974011",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Save factPayment as Delta table\n",
    "silver_payments_df.write.format(\"delta\")\\\n",
    "        .mode(\"overwrite\")\\\n",
    "        .option(\"overwriteSchema\", \"true\")\\\n",
    "        .saveAsTable(\"gold_fact_payments\")\n",
    "\n",
    "# Save dimRiders as Delta table\n",
    "silver_riders_df.write.format(\"delta\")\\\n",
    "        .mode(\"overwrite\")\\\n",
    "        .option(\"overwriteSchema\", \"true\")\\\n",
    "        .saveAsTable(\"gold_dim_riders\")\n",
    "\n",
    "# Save dimStations as Delta table\n",
    "silver_stations_df.write.format(\"delta\")\\\n",
    "        .mode(\"overwrite\")\\\n",
    "        .option(\"overwriteSchema\", \"true\")\\\n",
    "        .saveAsTable(\"gold_dim_stations\")\n",
    "\n",
    "# Create and save factTrips as Delta table\n",
    "gold_trips_df = spark.sql(\"\"\"\n",
    "    SELECT tr.trip_id,\n",
    "           tr.start_time,\n",
    "           tr.end_time,\n",
    "           tr.type_of_rideable,\n",
    "           tr.start_station,\n",
    "           tr.end_station,\n",
    "           DATEDIFF(YEAR, r.dob, tr.start_time) AS rider_age_at_trip_start,\n",
    "           DATEDIFF(SECOND, tr.start_time, tr.end_time) AS trip_duration_in_seconds,\n",
    "           r.acc_number\n",
    "    FROM silver_trips tr\n",
    "    LEFT JOIN silver_riders r ON tr.acc_number = r.acc_number\n",
    "\"\"\")\n",
    "\n",
    "gold_trips_df.write.format(\"delta\")\\\n",
    "        .mode(\"overwrite\")\\\n",
    "        .option(\"overwriteSchema\", \"true\")\\\n",
    "        .saveAsTable(\"gold_fact_trips\")\n",
    "\n",
    "\n",
    "# Create and save dimTime as Delta table\n",
    "temp_time_df = spark.sql(\"\"\"\n",
    "    SELECT start_time AS syncTime FROM silver_trips\n",
    "    UNION\n",
    "    SELECT end_time AS syncTime FROM silver_trips\n",
    "    UNION\n",
    "    SELECT payment_date AS syncTime FROM silver_payments\n",
    "\"\"\")\n",
    "\n",
    "gold_time_df = temp_time_df.withColumn(\"datetime\", col(\"syncTime\"))\\\n",
    "                           .withColumn(\"dayofweek\", when(dayofweek(col(\"syncTime\")) == 1, \"Sunday\")\n",
    "                                                   .when(dayofweek(col(\"syncTime\")) == 2, \"Monday\")\n",
    "                                                   .when(dayofweek(col(\"syncTime\")) == 3, \"Tuesday\")\n",
    "                                                   .when(dayofweek(col(\"syncTime\")) == 4, \"Wednesday\")\n",
    "                                                   .when(dayofweek(col(\"syncTime\")) == 5, \"Thursday\")\n",
    "                                                   .when(dayofweek(col(\"syncTime\")) == 6, \"Friday\")\n",
    "                                                   .when(dayofweek(col(\"syncTime\")) == 7, \"Saturday\"))\\\n",
    "                           .withColumn(\"day\", dayofmonth(col(\"syncTime\")))\\\n",
    "                           .withColumn(\"month\", month(col(\"syncTime\")))\\\n",
    "                           .withColumn(\"quarter\", quarter(col(\"syncTime\")))\\\n",
    "                           .withColumn(\"year\", year(col(\"syncTime\")))\\\n",
    "                           .withColumn(\"hourOfDay\", hour(col(\"syncTime\")))\\\n",
    "                           .withColumn(\"minute\", minute(col(\"syncTime\")))\\\n",
    "                           .withColumn(\"second\", second(col(\"syncTime\")))\n",
    "\n",
    "gold_time_df.write.format(\"delta\")\\\n",
    "        .mode(\"overwrite\")\\\n",
    "        .option(\"overwriteSchema\", \"true\")\\\n",
    "        .saveAsTable(\"gold_dim_time\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "tungpham",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
